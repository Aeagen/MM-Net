EquiUnet(
  (act): ReLU(inplace=True)
  (downsample0): Conv_down(
    (conv1): Conv3d(4, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
    (norm): GroupNorm(16, 48, eps=1e-05, affine=True)
    (act): ReLU()
  )
  (encoder1): UBlockCbam(
    (UBlock): UBlock(
      (ConvBnRelu1): ConvBnRelu(
        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn): GroupNorm(16, 48, eps=1e-05, affine=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (ConvBnRelu2): ConvBnRelu(
        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
        (bn): GroupNorm(16, 48, eps=1e-05, affine=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
    (CBAM): CBAM(
      (ChannelGate): ChannelGate(
        (mlp): Sequential(
          (0): Flatten()
          (1): Linear(in_features=48, out_features=3, bias=True)
          (2): ReLU(inplace=True)
          (3): Linear(in_features=3, out_features=48, bias=True)
        )
      )
      (SpatialGate): SpatialGate(
        (compress): ChannelPool()
        (spatial): BasicConv(
          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)
          (bn): GroupNorm(1, 1, eps=1e-05, affine=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
  )
  (downsample1): Conv_down(
    (conv1): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
    (norm): GroupNorm(16, 96, eps=1e-05, affine=True)
    (act): ReLU()
  )
  (encoder2): Sequential(
    (0): AxialBlock(
      (conv_down): Conv3d(96, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): GroupNorm(16, 96, eps=1e-05, affine=True)
      (hight_block): AxialAttention(
        (qkv_transform): qkv_transform(96, 192, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=96, out_features=192, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=192, out_features=96, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=192, out_features=96, bias=False)
      )
      (width_block): AxialAttention(
        (qkv_transform): qkv_transform(96, 192, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=96, out_features=192, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=192, out_features=96, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=192, out_features=96, bias=False)
      )
      (depth_block): AxialAttention(
        (qkv_transform): qkv_transform(96, 192, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=96, out_features=192, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=192, out_features=96, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=192, out_features=96, bias=False)
      )
      (conv_up1): Conv3d(96, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (conv_up2): Conv3d(96, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn2): GroupNorm(16, 96, eps=1e-05, affine=True)
      (relu): ReLU()
      (mlp): Sequential(
        (0): Flatten()
        (1): Linear(in_features=96, out_features=6, bias=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=6, out_features=96, bias=True)
      )
      (SpatialGate): SpatialGate(
        (compress): ChannelPool()
        (spatial): BasicConv(
          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)
          (bn): GroupNorm(1, 1, eps=1e-05, affine=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
  )
  (encoder2_1): UBlock333(
    (ConvBnRelu1): ConvBnRelu(
      (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 96, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (conv111_2): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  (downsample2): Conv_down(
    (conv1): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
    (norm): GroupNorm(16, 192, eps=1e-05, affine=True)
    (act): ReLU()
  )
  (encoder3): Sequential(
    (0): AxialBlock(
      (conv_down): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): GroupNorm(16, 192, eps=1e-05, affine=True)
      (hight_block): AxialAttention(
        (qkv_transform): qkv_transform(192, 384, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=384, out_features=192, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=384, out_features=192, bias=False)
      )
      (width_block): AxialAttention(
        (qkv_transform): qkv_transform(192, 384, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=384, out_features=192, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=384, out_features=192, bias=False)
      )
      (depth_block): AxialAttention(
        (qkv_transform): qkv_transform(192, 384, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=192, out_features=384, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=384, out_features=192, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=384, out_features=192, bias=False)
      )
      (conv_up1): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (conv_up2): Conv3d(192, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn2): GroupNorm(16, 192, eps=1e-05, affine=True)
      (relu): ReLU()
      (mlp): Sequential(
        (0): Flatten()
        (1): Linear(in_features=192, out_features=12, bias=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=12, out_features=192, bias=True)
      )
      (SpatialGate): SpatialGate(
        (compress): ChannelPool()
        (spatial): BasicConv(
          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)
          (bn): GroupNorm(1, 1, eps=1e-05, affine=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
  )
  (encoder3_1): UBlock333(
    (ConvBnRelu1): ConvBnRelu(
      (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 192, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (conv111_3): Conv3d(384, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  (downsample3): Conv_down(
    (conv1): Conv3d(192, 384, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
    (norm): GroupNorm(16, 384, eps=1e-05, affine=True)
    (act): ReLU()
  )
  (encoder4): Sequential(
    (0): AxialBlock(
      (conv_down): Conv3d(384, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): GroupNorm(16, 384, eps=1e-05, affine=True)
      (hight_block): AxialAttention(
        (qkv_transform): qkv_transform(384, 768, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=384, out_features=768, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=768, out_features=384, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=768, out_features=384, bias=False)
      )
      (width_block): AxialAttention(
        (qkv_transform): qkv_transform(384, 768, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=384, out_features=768, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=768, out_features=384, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=768, out_features=384, bias=False)
      )
      (depth_block): AxialAttention(
        (qkv_transform): qkv_transform(384, 768, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=384, out_features=768, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=768, out_features=384, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=768, out_features=384, bias=False)
      )
      (conv_up1): Conv3d(384, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (conv_up2): Conv3d(384, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn2): GroupNorm(16, 384, eps=1e-05, affine=True)
      (relu): ReLU()
      (mlp): Sequential(
        (0): Flatten()
        (1): Linear(in_features=384, out_features=24, bias=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=24, out_features=384, bias=True)
      )
      (SpatialGate): SpatialGate(
        (compress): ChannelPool()
        (spatial): BasicConv(
          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)
          (bn): GroupNorm(1, 1, eps=1e-05, affine=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
  )
  (encoder4_1): UBlock333(
    (ConvBnRelu1): ConvBnRelu(
      (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 384, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (conv111_4): Conv3d(768, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  (bottom): Sequential(
    (0): AxialBlock(
      (conv_down): Conv3d(384, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): GroupNorm(16, 384, eps=1e-05, affine=True)
      (hight_block): AxialAttention(
        (qkv_transform): qkv_transform(384, 768, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=384, out_features=768, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=768, out_features=384, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=768, out_features=384, bias=False)
      )
      (width_block): AxialAttention(
        (qkv_transform): qkv_transform(384, 768, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=384, out_features=768, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=768, out_features=384, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=768, out_features=384, bias=False)
      )
      (depth_block): AxialAttention(
        (qkv_transform): qkv_transform(384, 768, kernel_size=(1,), stride=(1,), bias=False)
        (bn_qkv): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (bn_similarity): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (bn_output): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (mlps): Sequential(
          (0): Linear(in_features=384, out_features=768, bias=False)
          (1): ReLU()
          (2): Dropout(p=0.0, inplace=False)
          (3): Linear(in_features=768, out_features=384, bias=False)
          (4): Dropout(p=0.0, inplace=False)
        )
        (fc): Linear(in_features=768, out_features=384, bias=False)
      )
      (conv_up1): Conv3d(384, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (conv_up2): Conv3d(384, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn2): GroupNorm(16, 384, eps=1e-05, affine=True)
      (relu): ReLU()
      (mlp): Sequential(
        (0): Flatten()
        (1): Linear(in_features=384, out_features=24, bias=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=24, out_features=384, bias=True)
      )
      (SpatialGate): SpatialGate(
        (compress): ChannelPool()
        (spatial): BasicConv(
          (conv): Conv3d(2, 1, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), bias=False)
          (bn): GroupNorm(1, 1, eps=1e-05, affine=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (1): UBlock(
      (ConvBnRelu1): ConvBnRelu(
        (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)
        (bn): GroupNorm(16, 384, eps=1e-05, affine=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
      (ConvBnRelu2): ConvBnRelu(
        (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)
        (bn): GroupNorm(16, 384, eps=1e-05, affine=True)
        (relu): ReLU(inplace=True)
        (dropout): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (bottom_2): Sequential(
    (0): ConvBnRelu(
      (conv): Conv3d(768, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 192, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (downsample): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (decoder3): UBlock(
    (ConvBnRelu1): ConvBnRelu(
      (conv): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 192, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (ConvBnRelu2): ConvBnRelu(
      (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 96, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (decoder2): UBlock(
    (ConvBnRelu1): ConvBnRelu(
      (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 96, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (ConvBnRelu2): ConvBnRelu(
      (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 48, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (decoder1): UBlock(
    (ConvBnRelu1): ConvBnRelu(
      (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 48, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (ConvBnRelu2): ConvBnRelu(
      (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)
      (bn): GroupNorm(16, 48, eps=1e-05, affine=True)
      (relu): ReLU(inplace=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
  )
  (upsample): Upsample(scale_factor=2.0, mode=trilinear)
  (outconv): Conv3d(48, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
)
